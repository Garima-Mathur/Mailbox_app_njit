{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "garima2_(1) (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Garima-Mathur/Mailbox_app_njit/blob/master/garima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCJQb7TCmX06"
      },
      "source": [
        "HW1:   S&P500 Index Prediction\n",
        "\n",
        " \n",
        "\n",
        "The objectives of this homework are to (1) implement gradient descent by yourself and (2) get familiar with model selection.\n",
        "\n",
        "Due time: 11:30AM on Sep. 13 Monday. Submit through Canvas.\n",
        "\n",
        " \n",
        "\n",
        "Dataset:\n",
        "\n",
        "Training data: SPY close prices of 2017-2020\n",
        "\n",
        "Testing data: SPY close prices of Jan. 2021- Aug. 2021.\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "Problem formulation:  Given the previous N data points, you are going to predict the next value. n=1, ……, N.   N is a hyperparameter.\n",
        "\n",
        " \n",
        "\n",
        "Model function: Linear function xt = f(xt-n, xt-n+1, …, xt-1)\n",
        "\n",
        " \n",
        "\n",
        "Loss function: MSE\n",
        "\n",
        " \n",
        "\n",
        "Find the best N. Report loss for both training and testing data from 1 to the identified N.  Show the values in a table and also plot them. For the best N, report the weights.\n",
        "\n",
        " \n",
        "\n",
        "Suppose your best linear model is\n",
        "\n",
        "xt’ = b2 * xt-2 + b1 * xt-1 + b0\n",
        "\n",
        "You should report the best parameters, the function F and the value of N.\n",
        "\n",
        "For example\n",
        "\n",
        "xt’ = 0.83 * xt-2 + 0.54 *  xt-1 - 4.5 and N=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCMOu21QH8iv"
      },
      "source": [
        "Input variable: X \n",
        "\n",
        "Output variable: y_hat, the prediction \n",
        "\n",
        "Linear model: y_hat = b0 + b1x1 + b2x2 + … + bnxn\n",
        "\n",
        " \n",
        "\n",
        "xi is the ith feature in the input variable. By introducing x0 = 1, we can rewrite this equation.\n",
        "\n",
        " \n",
        "\n",
        "y_hat = b0x0 + b1x1 + b2x2 + … + bnxn\n",
        "\n",
        " \n",
        "\n",
        "Convert it to matrix form: \n",
        "\n",
        " \n",
        "\n",
        "y_hat = BTX  (T is transpose sign)\n",
        "\n",
        " \n",
        "\n",
        "Where B = [b0  b1 b2 … bn]T  and X = [x0  x1 x2 … xn]T\n",
        "\n",
        " \n",
        "\n",
        "Use MSE as the loss function: \n",
        "\n",
        " \n",
        "\n",
        "J(B) = 1/(2m) * sum(y_hati - yi)2, where m is the total number of samples.\n",
        "\n",
        " \n",
        "\n",
        "By minimizing this cost function, we can find weights B. You are required to use Gradient Descent.\n",
        "\n",
        " \n",
        "\n",
        "Gradient Descent\n",
        "\n",
        " \n",
        "\n",
        "Step 1: initialize values b0  b1 b2 … bn with some value. For example, random numbers or 0s.\n",
        "\n",
        "Step 2: iteratively update, bj := bj - a * [d J(B)/ d bj] until it converges, i.e., when the loss does not decrease. a is the learning rate. You choose this value and you can test different values. \n",
        "\n",
        "[d J(B)/ d bj] is the partial derivative of cost with respect to each bj\n",
        "\n",
        " \n",
        "\n",
        "After solving the above function, we have\n",
        "\n",
        " \n",
        "\n",
        "bj:= bj - a * (1/m) * sum[(y_hati - yi) * xi]\n",
        "\n",
        " \n",
        "\n",
        "We can vectorize all the equations so that all the bj can be calculated at the same time (no need to hard-code).\n",
        "\n",
        " \n",
        "\n",
        "Check this post if you are not familiar with vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlPo9vxln1AA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YnbyS75Q-oE"
      },
      "source": [
        "#ls '/content/drive/My drive/FALL_2021_ALL/DL'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "k9q0u01KmabK",
        "outputId": "8d0d9851-5b05-461c-f718-ea939bd7e8d4"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d8d1f48-5850-4163-ab24-4cc56b104acb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9d8d1f48-5850-4163-ab24-4cc56b104acb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SPY_CLOSE.csv to SPY_CLOSE.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34i_qIhmn36A"
      },
      "source": [
        "import io\n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['SPY_CLOSE.csv'])) #pandas dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "p2NTKOBIn9UX",
        "outputId": "5cb0b351-45b6-4c2e-c36c-8a083d8b1364"
      },
      "source": [
        "df2.head()\n",
        "df2.tail()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1168</th>\n",
              "      <td>8/24/2021</td>\n",
              "      <td>447.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1169</th>\n",
              "      <td>8/25/2021</td>\n",
              "      <td>448.910004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1170</th>\n",
              "      <td>8/26/2021</td>\n",
              "      <td>446.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>8/27/2021</td>\n",
              "      <td>450.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1172</th>\n",
              "      <td>8/30/2021</td>\n",
              "      <td>452.230011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date       Close\n",
              "1168  8/24/2021  447.970001\n",
              "1169  8/25/2021  448.910004\n",
              "1170  8/26/2021  446.260010\n",
              "1171  8/27/2021  450.250000\n",
              "1172  8/30/2021  452.230011"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLtCpgsRugpu"
      },
      "source": [
        "df2['Date'] = pd.to_datetime(df2['Date'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OHBIYDFvNKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fe55f1-a66f-4406-ceb5-6660113237b9"
      },
      "source": [
        "train_df = df2[df2['Date'] < '2021-01-01']\n",
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1007, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PseYgnuozEN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e5a0e4-7591-40c0-b960-7ffc406d78ad"
      },
      "source": [
        "test_df = df2[df2['Date'] >= '2021-01-01']\n",
        "test_df.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQqrHFAb0KbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bbf698e-17de-4c58-9ce4-04210186ac9c"
      },
      "source": [
        "Try = train_df.iloc[:,1][1:150]\n",
        "prepared_try= Try.values.flatten()\n",
        "prepared_try.shape\n",
        "Test_Try = test_df.iloc[:,1][1:150]\n",
        "prepared_test_try= Test_Try.values.flatten()\n",
        "prepared_test_try.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUne__9VkGtR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "cc215212-cad0-4196-98cd-d13b2f830960"
      },
      "source": [
        "# data preparation-Training \n",
        "for N_train in range(1,150):\n",
        "  x = []\n",
        "  y = []\n",
        "  i = 0\n",
        "  for i in range(len(prepared_try)-N_train):\n",
        "    subarray = prepared_try[i: i+N_train+1]\n",
        "    feature = subarray[:-1]\n",
        "    label = [subarray[-1]]\n",
        "    x.append(feature)\n",
        "    X = np.array(x)\n",
        "    y.append(label)\n",
        "    Y = np.array(y)\n",
        "    m = 0\n",
        "    c = 0\n",
        "    L = 0.00000001  # The learning Rate\n",
        "    epochs = 1500  # The number of iterations to perform gradient descent\n",
        "    n = float(len(X)) # Number of elements in X # Performing Gradient Descent \n",
        "    for j in range(epochs): \n",
        "      Y_pred = m*X + c  # The current predicted value of Y\n",
        "      cost = sum([data**2 for data in (Y-Y_pred)]) / n\n",
        "      cost_train=cost.min()\n",
        "      D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n",
        "      D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n",
        "      m = m - L * D_m  # Update m\n",
        "      c = c - L * D_c  # Update c\n",
        "  print( N_train,cost_train)\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.plot(N_train,cost_train,color='green',linestyle='dashed',linewidth=3,marker='o',markerfacecolor='blue', markersize='12')\n",
        "\n",
        "# data preparation-Testing \n",
        "for N_test in range(1,150):\n",
        "  x = []\n",
        "  y = []\n",
        "  i = 0\n",
        "  for i in range(len(prepared_test_try)-N_test):\n",
        "    subarray = prepared_test_try[i: i+N_test+1]\n",
        "    feature = subarray[:-1]\n",
        "    label = [subarray[-1]]\n",
        "    x.append(feature)\n",
        "    X = np.array(x)\n",
        "    y.append(label)\n",
        "    Y = np.array(y)\n",
        "    m = 0\n",
        "    c = 0\n",
        "    L = 0.00000001  # The learning Rate\n",
        "    epochs = 1500  # The number of iterations to perform gradient descent\n",
        "    n = float(len(X)) # Number of elements in X # Performing Gradient Descent \n",
        "    for j in range(epochs): \n",
        "      Y_pred = m*X + c  # The current predicted value of Y\n",
        "      cost = sum([data**2 for data in (Y-Y_pred)]) / n\n",
        "      cost_test = cost.min()\n",
        "      D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n",
        "      D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n",
        "      m = m - L * D_m  # Update m\n",
        "      c = c - L * D_c  # Update c\n",
        "  print( N_test,cost_test)\n",
        "  plt.plot(N_test,cost_test,color='green',linestyle='dashed',linewidth=3,marker='o',markerfacecolor='red', markersize='12')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.3492138035733434\n",
            "2 0.19354293640649145\n",
            "3 0.1568343885058689\n",
            "4 0.1787505066523809\n",
            "5 0.07525604675984479\n",
            "6 0.024334390838499195\n",
            "7 0.012894505343636273\n",
            "8 9.340208146384415e-05\n",
            "9 0.0\n",
            "10 0.0\n",
            "1 4.96457364477811e+84\n",
            "2 8.382384420456214e+84\n",
            "3 6.283549019305428e+84\n",
            "4 2.481293416302043e+84\n",
            "5 1.1135001923246183e+84\n",
            "6 3.5021061330657045e+83\n",
            "7 5.9306666358913715e+81\n",
            "8 2.2980986650853714e+79\n",
            "9 1.421992745205908e+78\n",
            "10 1.421992745205908e+78\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyO6KaTSr6Qq",
        "outputId": "f366825a-d728-4a29-c373-1a97eb38bdb8"
      },
      "source": [
        "Test_Try = test_df.iloc[:,1][1:11]\n",
        "prepared_test_try= Test_Try.values.flatten()\n",
        "prepared_test_try.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "78WdgUlxsWoC",
        "outputId": "6eca86c4-e541-45d7-d7e9-b619e40876af"
      },
      "source": [
        "# \n",
        "'''data preparation-Testing \n",
        "for N_test in range(1,11):\n",
        "  x = []\n",
        "  y = []\n",
        "  i = 0\n",
        "  for i in range(len(prepared_test_try)-N_test):\n",
        "    subarray = prepared_test_try[i: i+N_test+1]\n",
        "    feature = subarray[:-1]\n",
        "    label = [subarray[-1]]\n",
        "    x.append(feature)\n",
        "    X = np.array(x)\n",
        "    y.append(label)\n",
        "    Y = np.array(y)\n",
        "    m = 0\n",
        "    c = 0\n",
        "    L = 0.00001  # The learning Rate\n",
        "    epochs = 150  # The number of iterations to perform gradient descent\n",
        "    n = float(len(X)) # Number of elements in X # Performing Gradient Descent \n",
        "    for j in range(epochs): \n",
        "      Y_pred = m*X + c  # The current predicted value of Y\n",
        "      cost = sum([data**2 for data in (Y-Y_pred)]) / n\n",
        "      cost_test = cost.min()\n",
        "      D_m = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n",
        "      D_c = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n",
        "      m = m - L * D_m  # Update m\n",
        "      c = c - L * D_c  # Update c\n",
        "  print( N_test,cost_test)'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-40769863f37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_test_try\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msubarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepared_test_try\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubarray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'prepared_test_try' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "UkltGVCu0JKo",
        "outputId": "86647da1-1cd3-46f2-847d-973687539376"
      },
      "source": [
        "'''import matplotlib.pyplot as plt\n",
        "plt.plot(N_train,cost_train)\n",
        "#plt.plot(N_test,cost_test, 'o:r')\n",
        "plt.show()'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3fd6545f1741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.plot(N_test,cost_test, 'o:r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'N_train' is not defined"
          ]
        }
      ]
    }
  ]
}